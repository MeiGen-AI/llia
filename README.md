<div align="center">
<h1>LLIA - Enabling Low-Latency Interactive Avatars: Real-Time Audio-Driven Portrait Video Generation with Diffusion Models</h1>


Haojie Yu* · Zhaonian Wang* · Yihan Pan* · Meng Cheng · Hao Yang · Chao Wang · Tao Xie · Xiaoming Xu<sup>&#9993;</sup> · [Xiaoming Wei](https://scholar.google.com/citations?user=JXV5yrZxj5MC&hl=zh-CN) · [Xunliang Cai](https://openreview.net/profile?id=~Xunliang_Cai1) 

<sup>*</sup>Equal Contribution
<sup>&#9993;</sup>Corresponding Authors


<a href='https://meigen-ai.github.io/llia/'><img src='https://img.shields.io/badge/Project-Page-green'></a>
<a href='https://arxiv.org/abs/2506.05806'><img src='https://img.shields.io/badge/Technique-Report-red'></a>
</div>

> **TL; DR:**  LLIA is a real-time audio-driven portrait video generation with diffusion models, enabling low-latency interactive avatars.

<!-- <p align="center">
  <img src="assets/pipe.png">
</p> -->

<!-- ## Video Demos -->



## 🔆 Introduction

We propose **LLIA** , a novel audio-driven portrait video generation framework based on the diffusion model. Our approach achieves low-latency, fluid, and authentic two-way communication. On an NVIDIA RTX 4090D, our model achieves a maximum of 78 FPS at a resolution of 384 × 384 and 45 FPS at a resolution of 512 × 512, with an initial video generation latency of 140 ms and 215 ms, respectively


## 🔥 Latest News

* June 9, 2025: 👋 We release the [Technique-Report](https://arxiv.org/abs/2506.05806) of **LLIA** 
* June 9, 2025: 👋 We release the [project page](https://meigen-ai.github.io/llia/) of **LLIA** 


# CODE COMING SOON!
<!-- ## 📑 Todo List

- [x] Release the technical report
- [ ] Inference
- [ ] Checkpoints -->
